{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单的多层感知机\n",
    "- 和softmax回归唯一的不同在于，我们多加了一个全连接层作为隐藏层。它的隐藏单元个数为256，并使用ReLU函数作为激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(256, activation='relu',),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fashion_mnist = keras.datasets.fashion_mnist\n",
    "# (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# x_train = x_train / 255.0\n",
    "# x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.5),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          validation_data = (x_test,y_test),\n",
    "          validation_freq = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 简单的线性分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "features = tf.random.normal((num_examples, num_inputs), stddev = 1)\n",
    "labels = true_w[0] * features[:,0] + true_w[1] * features[:,1] + true_b\n",
    "labels += tf.random.normal(labels.shape,stddev=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x14240a390>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "set_figsize()\n",
    "plt.scatter(features[:, 1], labels, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写模型不可缺少的步骤和实现方式,以手动构建线性回归举例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.读取数据\n",
    "- 在训练模型的时候，我们需要遍历数据集并不断读取小批量数据样本。这里我们定义一个函数：它每次返回batch_size（批量大小）个随机样本的特征和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = indices[i:min(i+batch_size,num_examples)]\n",
    "        yield tf.gather(features, axis=0, indices=j), tf.gather(labels, axis=0, indices=j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们读取第一个小批量数据样本并打印。每个批量的特征形状为(10, 2)，分别对应批量大小和输入个数；标签形状为批量大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.0009625  -1.0014906 ]\n",
      " [-0.92488134 -0.08524901]\n",
      " [ 1.2781938  -0.8333126 ]\n",
      " [-0.63596976 -0.80683005]\n",
      " [-1.0557224  -0.36221355]\n",
      " [ 1.8000348   1.6206416 ]\n",
      " [ 0.06235145  0.60999733]\n",
      " [-0.9459097   0.65752953]\n",
      " [-1.3117768   0.10646594]\n",
      " [ 0.3443827  -1.061503  ]], shape=(10, 2), dtype=float32) tf.Tensor(\n",
      "[5.6033945  2.63592    9.59115    5.6887155  3.3222578  2.3041556\n",
      " 2.240062   0.07481673 1.1997888  8.486421  ], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.初始化模型参数\n",
    "- 我们将权重初始化成均值为0、标准差为0.01的正态随机数，偏差则初始化成0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.normal((num_inputs, 1), stddev=0.01))\n",
    "b = tf.Variable(tf.zeros((1,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(x,w,b):\n",
    "    return tf.matmul(x,w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):\n",
    "    return (y_hat - tf.reshape(y, y_hat.shape)) ** 2 /2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.定义优化算法\n",
    "- 以下的sgd函数实现了小批量随机梯度下降算法。它通过不断迭代模型参数来优化损失函数。这里自动求梯度模块计算得来的梯度是一个批量样本的梯度和。我们将它除以批量大小来得到平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size, grads):\n",
    "    \"\"\"Mini-batch stochastic gradient descent.\"\"\"\n",
    "    for i, param in enumerate(params):\n",
    "        param.assign_sub(lr * grads[i]/batch_size)#不改变内存地址上进行更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.训练模型\n",
    "- 在训练中，我们将多次迭代模型参数。在每次迭代中，我们根据当前读取的小批量数据样本（特征X和标签y），通过调用反向函数t.gradients计算小批量随机梯度，并调用优化算法sgd迭代模型参数。由于我们之前设批量大小batch_size为10，每个小批量的损失l的形状为(10, 1)。回忆一下自动求梯度一节。由于变量l并不是一个标量，所以我们可以调用reduce_sum()将其求和得到一个标量，再运行t.gradients得到该变量有关模型参数的梯度。注意在每次更新完参数后不要忘了将参数的梯度清零。\n",
    "\n",
    "- 在一个迭代周期（epoch）中，我们将完整遍历一遍data_iter函数，并对训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。这里的迭代周期个数num_epochs和学习率lr都是超参数，分别设3和0.03。在实践中，大多超参数都需要通过反复试错来不断调节。虽然迭代周期数设得越大模型可能越有效，但是训练时间可能过长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000050\n",
      "epoch 2, loss 0.000050\n",
      "epoch 3, loss 0.000050\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        with tf.GradientTape() as t:\n",
    "            t.watch([w,b])\n",
    "            l = tf.reduce_sum(loss(net(X, w, b), y))\n",
    "        grads = t.gradient(l, [w, b])\n",
    "        sgd([w, b], lr, batch_size, grads)\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print('epoch %d, loss %f' % (epoch + 1, tf.reduce_mean(train_l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "features = tf.random.normal(shape=(num_examples, num_inputs), stddev=1)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += tf.random.normal(labels.shape, stddev=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import data as tfdata\n",
    "#(features, labels)  type: tf.Tensor\n",
    "batch_size = 10\n",
    "#将训练数据和标签组合\n",
    "dataset = tfdata.Dataset.from_tensor_slices((features, labels))\n",
    "#随机读取小批量\n",
    "dataset = dataset.shuffle(buffer_size=num_examples)\n",
    "dataset = dataset.batch(batch_size)\n",
    "#shuffle 的 buffer_size 参数应大于等于样本数，batch 可以指定 batch_size 的分割大小。\n",
    "data_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.2529511  -1.2222093 ]\n",
      " [-1.488042   -0.22310701]\n",
      " [ 1.910724   -0.07537813]\n",
      " [-0.68146527  0.5619334 ]\n",
      " [ 0.02452954  1.169147  ]\n",
      " [-0.08022968 -1.157499  ]\n",
      " [ 1.6391851   0.795107  ]\n",
      " [ 2.4685452  -0.01579604]\n",
      " [-0.6259472  -0.11549472]\n",
      " [ 0.37320036  1.964596  ]], shape=(10, 2), dtype=float32) tf.Tensor(\n",
      "[ 7.8532033   1.9714571   8.282044    0.9179813   0.27707317  7.968178\n",
      "  4.78043     9.176874    3.3433754  -1.7412081 ], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用iter(dataset)的方式，只能遍历数据集一次，是一种比较 tricky 的写法，为了复刻原书表达才这样写。这里也给出一种在官方文档中推荐的写法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.5757189   0.13524647]\n",
      " [-2.1819665  -1.3438616 ]\n",
      " [-1.2079039   0.72684574]\n",
      " [ 0.48520005 -1.42077   ]\n",
      " [ 1.1616789   0.99253273]\n",
      " [-1.6202601   1.5013831 ]\n",
      " [-0.50778884  0.7078269 ]\n",
      " [-0.57310194 -0.2932425 ]\n",
      " [-0.2513959   1.8250375 ]\n",
      " [-1.4601657  -0.49996945]], shape=(10, 2), dtype=float32) tf.Tensor(\n",
      "[ 4.876295   4.413867  -0.7000281 10.007149   3.1335862 -4.1454635\n",
      "  0.8011116  4.0598497 -2.5145519  2.9777775], shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for (batch, (X, y)) in enumerate(dataset):\n",
    "    print(X, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.定义模型和初始化参数\n",
    "- Tensorflow 2.0推荐使用Keras定义网络，故使用Keras定义网络 我们先定义一个模型变量model，它是一个Sequential实例。 在Keras中，Sequential实例可以看作是一个串联各个层的容器。\n",
    "\n",
    "- 在构造模型时，我们在该容器中依次添加层。 当给定输入数据时，容器中的每一层将依次推断下一层的输入尺寸。 重要的一点是，在Keras中我们无须指定每一层输入的形状。 线性回归，输入层与输出层等效为一层全连接层keras.layers.Dense()。\n",
    "\n",
    "- Keras 中初始化参数由 kernel_initializer 和 bias_initializer 选项分别设置权重和偏置的初始化方式。我们从 tensorflow 导入 initializers 模块，指定权重参数每个元素将在初始化时随机采样于均值为0、标准差为0.01的正态分布。偏差参数默认会初始化为零。RandomNormal(stddev=0.01)指定权重参数每个元素将在初始化时随机采样于均值为0、标准差为0.01的正态分布。偏差参数默认会初始化为零。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import initializers as init\n",
    "model = keras.models.Sequential([\n",
    "    layers.Dense(1, kernel_initializer=init.RandomNormal(stddev=0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.定义损失函数\n",
    "- Tensoflow在losses模块中提供了各种损失函数和自定义损失函数的基类，并直接使用它的均方误差损失作为模型的损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import losses\n",
    "loss = losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.定义优化算法\n",
    "- 同样，我们也无须自己实现小批量随机梯度下降算法。tensorflow.keras.optimizers 模块提供了很多常用的优化算法比如SGD、Adam和RMSProp等。下面我们创建一个用于优化model 所有参数的优化器实例，并指定学习率为0.03的小批量随机梯度下降（SGD）为优化算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "trainer = optimizers.SGD(learning_rate=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.训练模型\n",
    "- Tensorflow训练模型时，我们通过调用tensorflow.GradientTape记录动态图梯度，执行tape.gradient获得动态图中各变量梯度。通过 model.trainable_variables 找到需要更新的变量，并用 trainer.apply_gradients 更新权重，完成一步训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000203\n",
      "epoch 2, loss: 0.000104\n",
      "epoch 3, loss: 0.000103\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for (batch, (x,y)) in enumerate(dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out = model(x,training=True)\n",
    "            l = loss(out,y)\n",
    "        grads = tape.gradient(l, model.trainable_variables)#计算梯度\n",
    "        trainer.apply_gradients(zip(grads, model.trainable_variables))#更新权重\n",
    "        \n",
    "    l = loss(model(features),labels)\n",
    "    print('epoch %d, loss: %f' % (epoch, l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们分别比较学到的模型参数和真实的模型参数。我们可以通过model的get_weights()来获得其权重（weight）和偏差（bias）。学到的参数和真实的参数很接近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
